optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0005,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ModelNet40HDF5.yaml,
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ModelNet40HDF5.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ModelNet40HDF5.yaml,
            others: {subset: 'test'}}}

model : {
  NAME: PointTransformer_RoPE,  # Use RoPE version
  trans_dim: 384,
  depth: 12,
  drop_path_rate: 0.1,
  cls_dim: 40,
  num_heads: 8,  # MUST match pretrain config! (head_dim=48 is divisible by 6)
  group_size: 32,
  num_group: 64,
  encoder_dims: 384,
  learner_type: 'cayley',  # Specify Cayley RoPE
}

# Load pretrained weights from Cayley RoPE
pretrained_path: experiments/pretrain/cfgs/pretrain_rope_cayley/ckpt-last.pth

npoints: 1024
total_bs : 32
step_per_update : 1
max_epoch : 300
grad_norm_clip : 10